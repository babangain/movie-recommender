{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "colab_type": "code",
    "id": "X2BtGU3iNPLt",
    "outputId": "ee1b22f6-0988-43cf-f0d8-8032f1203c15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.16.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.3.1)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.8.4)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.216)\n",
      "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.216 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.216)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.6.16)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.216->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.216->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SiVzvfbPOJOf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "directory = os.getcwd() \n",
    "import nltk\n",
    "import gensim \n",
    "import os\n",
    "from os import listdir\n",
    "from gensim import models\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import corpora, models, similarities\n",
    "import logging\n",
    "import time\n",
    "import re\n",
    "import io\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "j_uVEcY7Ookc",
    "outputId": "bafbad22-4721-45c5-8bf6-71054ce9d988"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/baban/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('movies_metadata.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 662
    },
    "colab_type": "code",
    "id": "E3mZN2I4P5Ba",
    "outputId": "d60c3384-c295-44e9-9a72-73d641f4ae70"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000000</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>81452156.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>False</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "3  False                                                NaN  16000000   \n",
       "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
       "4                     [{'id': 35, 'name': 'Comedy'}]   \n",
       "\n",
       "                               homepage     id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
       "1                                   NaN   8844  tt0113497                en   \n",
       "2                                   NaN  15602  tt0113228                en   \n",
       "3                                   NaN  31357  tt0114885                en   \n",
       "4                                   NaN  11862  tt0113041                en   \n",
       "\n",
       "                original_title  \\\n",
       "0                    Toy Story   \n",
       "1                      Jumanji   \n",
       "2             Grumpier Old Men   \n",
       "3            Waiting to Exhale   \n",
       "4  Father of the Bride Part II   \n",
       "\n",
       "                                            overview    ...     release_date  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...    ...       1995-10-30   \n",
       "1  When siblings Judy and Peter discover an encha...    ...       1995-12-15   \n",
       "2  A family wedding reignites the ancient feud be...    ...       1995-12-22   \n",
       "3  Cheated on, mistreated and stepped on, the wom...    ...       1995-12-22   \n",
       "4  Just when George Banks has recovered from his ...    ...       1995-02-10   \n",
       "\n",
       "       revenue runtime                                   spoken_languages  \\\n",
       "0  373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "1  262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
       "2          0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "3   81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "4   76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "\n",
       "     status                                            tagline  \\\n",
       "0  Released                                                NaN   \n",
       "1  Released          Roll the dice and unleash the excitement!   \n",
       "2  Released  Still Yelling. Still Fighting. Still Ready for...   \n",
       "3  Released  Friends are the people who let you be yourself...   \n",
       "4  Released  Just When His World Is Back To Normal... He's ...   \n",
       "\n",
       "                         title  video vote_average vote_count  \n",
       "0                    Toy Story  False          7.7     5415.0  \n",
       "1                      Jumanji  False          6.9     2413.0  \n",
       "2             Grumpier Old Men  False          6.5       92.0  \n",
       "3            Waiting to Exhale  False          6.1       34.0  \n",
       "4  Father of the Bride Part II  False          5.7      173.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kf6au2oBQEUU"
   },
   "outputs": [],
   "source": [
    "#We will consider movie name and overview only to predict\n",
    "title = list(data['original_title'])\n",
    "overview = data['overview'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jdZqolcJPPH3",
    "outputId": "e9b91dd6-0626-4ad9-bb6b-ebe5e45ad0d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/baban/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package words to /home/baban/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/baban/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceessing : 0\n",
      "Proceessing : 100\n",
      "Proceessing : 200\n",
      "Proceessing : 300\n",
      "Proceessing : 400\n",
      "Proceessing : 500\n",
      "Proceessing : 600\n",
      "Proceessing : 700\n",
      "Proceessing : 800\n",
      "Proceessing : 900\n",
      "Proceessing : 1000\n",
      "Proceessing : 1100\n",
      "Proceessing : 1200\n",
      "Proceessing : 1300\n",
      "Proceessing : 1400\n",
      "Proceessing : 1500\n",
      "Proceessing : 1600\n",
      "Proceessing : 1700\n",
      "Proceessing : 1800\n",
      "Proceessing : 1900\n",
      "Proceessing : 2000\n",
      "Proceessing : 2100\n",
      "Proceessing : 2200\n",
      "Proceessing : 2300\n",
      "Proceessing : 2400\n",
      "Proceessing : 2500\n",
      "Proceessing : 2600\n",
      "Proceessing : 2700\n",
      "Proceessing : 2800\n",
      "Proceessing : 2900\n",
      "Proceessing : 3000\n",
      "Proceessing : 3100\n",
      "Proceessing : 3200\n",
      "Proceessing : 3300\n",
      "Proceessing : 3400\n",
      "Proceessing : 3500\n",
      "Proceessing : 3600\n",
      "Proceessing : 3700\n",
      "Proceessing : 3800\n",
      "Proceessing : 3900\n",
      "Proceessing : 4000\n",
      "Proceessing : 4100\n",
      "Proceessing : 4200\n",
      "Proceessing : 4300\n",
      "Proceessing : 4400\n",
      "Proceessing : 4500\n",
      "Proceessing : 4600\n",
      "Proceessing : 4700\n",
      "Proceessing : 4800\n",
      "Proceessing : 4900\n",
      "Proceessing : 5000\n",
      "Proceessing : 5100\n",
      "Proceessing : 5200\n",
      "Proceessing : 5300\n",
      "Proceessing : 5400\n",
      "Proceessing : 5500\n",
      "Proceessing : 5600\n",
      "Proceessing : 5700\n",
      "Proceessing : 5800\n",
      "Proceessing : 5900\n",
      "Proceessing : 6000\n",
      "Proceessing : 6100\n",
      "Proceessing : 6200\n",
      "Proceessing : 6300\n",
      "Proceessing : 6400\n",
      "Proceessing : 6500\n",
      "Proceessing : 6600\n",
      "Proceessing : 6700\n",
      "Proceessing : 6800\n",
      "Proceessing : 6900\n",
      "Proceessing : 7000\n",
      "Proceessing : 7100\n",
      "Proceessing : 7200\n",
      "Proceessing : 7300\n",
      "Proceessing : 7400\n",
      "Proceessing : 7500\n",
      "Proceessing : 7600\n",
      "Proceessing : 7700\n",
      "Proceessing : 7800\n",
      "Proceessing : 7900\n",
      "Proceessing : 8000\n",
      "Proceessing : 8100\n",
      "Proceessing : 8200\n",
      "Proceessing : 8300\n",
      "Proceessing : 8400\n",
      "Proceessing : 8500\n",
      "Proceessing : 8600\n",
      "Proceessing : 8700\n",
      "Proceessing : 8800\n",
      "Proceessing : 8900\n",
      "Proceessing : 9000\n",
      "Proceessing : 9100\n",
      "Proceessing : 9200\n",
      "Proceessing : 9300\n",
      "Proceessing : 9400\n",
      "Proceessing : 9500\n",
      "Proceessing : 9600\n",
      "Proceessing : 9700\n",
      "Proceessing : 9800\n",
      "Proceessing : 9900\n",
      "Proceessing : 10000\n",
      "Proceessing : 10100\n",
      "Proceessing : 10200\n",
      "Proceessing : 10300\n",
      "Proceessing : 10400\n",
      "Proceessing : 10500\n",
      "Proceessing : 10600\n",
      "Proceessing : 10700\n",
      "Proceessing : 10800\n",
      "Proceessing : 10900\n",
      "Proceessing : 11000\n",
      "Proceessing : 11100\n",
      "Proceessing : 11200\n",
      "Proceessing : 11300\n",
      "Proceessing : 11400\n",
      "Proceessing : 11500\n",
      "Proceessing : 11600\n",
      "Proceessing : 11700\n",
      "Proceessing : 11800\n",
      "Proceessing : 11900\n",
      "Proceessing : 12000\n",
      "Proceessing : 12100\n",
      "Proceessing : 12200\n",
      "Proceessing : 12300\n",
      "Proceessing : 12400\n",
      "Proceessing : 12500\n",
      "Proceessing : 12600\n",
      "Proceessing : 12700\n",
      "Proceessing : 12800\n",
      "Proceessing : 12900\n",
      "Proceessing : 13000\n",
      "Proceessing : 13100\n",
      "Proceessing : 13200\n",
      "Proceessing : 13300\n",
      "Proceessing : 13400\n",
      "Proceessing : 13500\n",
      "Proceessing : 13600\n",
      "Proceessing : 13700\n",
      "Proceessing : 13800\n",
      "Proceessing : 13900\n",
      "Proceessing : 14000\n",
      "Proceessing : 14100\n",
      "Proceessing : 14200\n",
      "Proceessing : 14300\n",
      "Proceessing : 14400\n",
      "Proceessing : 14500\n",
      "Proceessing : 14600\n",
      "Proceessing : 14700\n",
      "Proceessing : 14800\n",
      "Proceessing : 14900\n",
      "Proceessing : 15000\n",
      "Proceessing : 15100\n",
      "Proceessing : 15200\n",
      "Proceessing : 15300\n",
      "Proceessing : 15400\n",
      "Proceessing : 15500\n",
      "Proceessing : 15600\n",
      "Proceessing : 15700\n",
      "Proceessing : 15800\n",
      "Proceessing : 15900\n",
      "Proceessing : 16000\n",
      "Proceessing : 16100\n",
      "Proceessing : 16200\n",
      "Proceessing : 16300\n",
      "Proceessing : 16400\n",
      "Proceessing : 16500\n",
      "Proceessing : 16600\n",
      "Proceessing : 16700\n",
      "Proceessing : 16800\n",
      "Proceessing : 16900\n",
      "Proceessing : 17000\n",
      "Proceessing : 17100\n",
      "Proceessing : 17200\n",
      "Proceessing : 17300\n",
      "Proceessing : 17400\n",
      "Proceessing : 17500\n",
      "Proceessing : 17600\n",
      "Proceessing : 17700\n",
      "Proceessing : 17800\n",
      "Proceessing : 17900\n",
      "Proceessing : 18000\n",
      "Proceessing : 18100\n",
      "Proceessing : 18200\n",
      "Proceessing : 18300\n",
      "Proceessing : 18400\n",
      "Proceessing : 18500\n",
      "Proceessing : 18600\n",
      "Proceessing : 18700\n",
      "Proceessing : 18800\n",
      "Proceessing : 18900\n",
      "Proceessing : 19000\n",
      "Proceessing : 19100\n",
      "Proceessing : 19200\n",
      "Proceessing : 19300\n",
      "Proceessing : 19400\n",
      "Proceessing : 19500\n",
      "Proceessing : 19600\n",
      "Proceessing : 19700\n",
      "Proceessing : 19800\n",
      "Proceessing : 19900\n",
      "Proceessing : 20000\n",
      "Proceessing : 20100\n",
      "Proceessing : 20200\n",
      "Proceessing : 20300\n",
      "Proceessing : 20400\n",
      "Proceessing : 20500\n",
      "Proceessing : 20600\n",
      "Proceessing : 20700\n",
      "Proceessing : 20800\n",
      "Proceessing : 20900\n",
      "Proceessing : 21000\n",
      "Proceessing : 21100\n",
      "Proceessing : 21200\n",
      "Proceessing : 21300\n",
      "Proceessing : 21400\n",
      "Proceessing : 21500\n",
      "Proceessing : 21600\n",
      "Proceessing : 21700\n",
      "Proceessing : 21800\n",
      "Proceessing : 21900\n",
      "Proceessing : 22000\n",
      "Proceessing : 22100\n",
      "Proceessing : 22200\n",
      "Proceessing : 22300\n",
      "Proceessing : 22400\n",
      "Proceessing : 22500\n",
      "Proceessing : 22600\n",
      "Proceessing : 22700\n",
      "Proceessing : 22800\n",
      "Proceessing : 22900\n",
      "Proceessing : 23000\n",
      "Proceessing : 23100\n",
      "Proceessing : 23200\n",
      "Proceessing : 23300\n",
      "Proceessing : 23400\n",
      "Proceessing : 23500\n",
      "Proceessing : 23600\n",
      "Proceessing : 23700\n",
      "Proceessing : 23800\n",
      "Proceessing : 23900\n",
      "Proceessing : 24000\n",
      "Proceessing : 24100\n",
      "Proceessing : 24200\n",
      "Proceessing : 24300\n",
      "Proceessing : 24400\n",
      "Proceessing : 24500\n",
      "Proceessing : 24600\n",
      "Proceessing : 24700\n",
      "Proceessing : 24800\n",
      "Proceessing : 24900\n",
      "Proceessing : 25000\n",
      "Proceessing : 25100\n",
      "Proceessing : 25200\n",
      "Proceessing : 25300\n",
      "Proceessing : 25400\n",
      "Proceessing : 25500\n",
      "Proceessing : 25600\n",
      "Proceessing : 25700\n",
      "Proceessing : 25800\n",
      "Proceessing : 25900\n",
      "Proceessing : 26000\n",
      "Proceessing : 26100\n",
      "Proceessing : 26200\n",
      "Proceessing : 26300\n",
      "Proceessing : 26400\n",
      "Proceessing : 26500\n",
      "Proceessing : 26600\n",
      "Proceessing : 26700\n",
      "Proceessing : 26800\n",
      "Proceessing : 26900\n",
      "Proceessing : 27000\n",
      "Proceessing : 27100\n",
      "Proceessing : 27200\n",
      "Proceessing : 27300\n",
      "Proceessing : 27400\n",
      "Proceessing : 27500\n",
      "Proceessing : 27600\n",
      "Proceessing : 27700\n",
      "Proceessing : 27800\n",
      "Proceessing : 27900\n",
      "Proceessing : 28000\n",
      "Proceessing : 28100\n",
      "Proceessing : 28200\n",
      "Proceessing : 28300\n",
      "Proceessing : 28400\n",
      "Proceessing : 28500\n",
      "Proceessing : 28600\n",
      "Proceessing : 28700\n",
      "Proceessing : 28800\n",
      "Proceessing : 28900\n",
      "Proceessing : 29000\n",
      "Proceessing : 29100\n",
      "Proceessing : 29200\n",
      "Proceessing : 29300\n",
      "Proceessing : 29400\n",
      "Proceessing : 29500\n",
      "Proceessing : 29600\n",
      "Proceessing : 29700\n",
      "Proceessing : 29800\n",
      "Proceessing : 29900\n",
      "Proceessing : 30000\n",
      "Proceessing : 30100\n",
      "Proceessing : 30200\n",
      "Proceessing : 30300\n",
      "Proceessing : 30400\n",
      "Proceessing : 30500\n",
      "Proceessing : 30600\n",
      "Proceessing : 30700\n",
      "Proceessing : 30800\n",
      "Proceessing : 30900\n",
      "Proceessing : 31000\n",
      "Proceessing : 31100\n",
      "Proceessing : 31200\n",
      "Proceessing : 31300\n",
      "Proceessing : 31400\n",
      "Proceessing : 31500\n",
      "Proceessing : 31600\n",
      "Proceessing : 31700\n",
      "Proceessing : 31800\n",
      "Proceessing : 31900\n",
      "Proceessing : 32000\n",
      "Proceessing : 32100\n",
      "Proceessing : 32200\n",
      "Proceessing : 32300\n",
      "Proceessing : 32400\n",
      "Proceessing : 32500\n",
      "Proceessing : 32600\n",
      "Proceessing : 32700\n",
      "Proceessing : 32800\n",
      "Proceessing : 32900\n",
      "Proceessing : 33000\n",
      "Proceessing : 33100\n",
      "Proceessing : 33200\n",
      "Proceessing : 33300\n",
      "Proceessing : 33400\n",
      "Proceessing : 33500\n",
      "Proceessing : 33600\n",
      "Proceessing : 33700\n",
      "Proceessing : 33800\n",
      "Proceessing : 33900\n",
      "Proceessing : 34000\n",
      "Proceessing : 34100\n",
      "Proceessing : 34200\n",
      "Proceessing : 34300\n",
      "Proceessing : 34400\n",
      "Proceessing : 34500\n",
      "Proceessing : 34600\n",
      "Proceessing : 34700\n",
      "Proceessing : 34800\n",
      "Proceessing : 34900\n",
      "Proceessing : 35000\n",
      "Proceessing : 35100\n",
      "Proceessing : 35200\n",
      "Proceessing : 35300\n",
      "Proceessing : 35400\n",
      "Proceessing : 35500\n",
      "Proceessing : 35600\n",
      "Proceessing : 35700\n",
      "Proceessing : 35800\n",
      "Proceessing : 35900\n",
      "Proceessing : 36000\n",
      "Proceessing : 36100\n",
      "Proceessing : 36200\n",
      "Proceessing : 36300\n",
      "Proceessing : 36400\n",
      "Proceessing : 36500\n",
      "Proceessing : 36600\n",
      "Proceessing : 36700\n",
      "Proceessing : 36800\n",
      "Proceessing : 36900\n",
      "Proceessing : 37000\n",
      "Proceessing : 37100\n",
      "Proceessing : 37200\n",
      "Proceessing : 37300\n",
      "Proceessing : 37400\n",
      "Proceessing : 37500\n",
      "Proceessing : 37600\n",
      "Proceessing : 37700\n",
      "Proceessing : 37800\n",
      "Proceessing : 37900\n",
      "Proceessing : 38000\n",
      "Proceessing : 38100\n",
      "Proceessing : 38200\n",
      "Proceessing : 38300\n",
      "Proceessing : 38400\n",
      "Proceessing : 38500\n",
      "Proceessing : 38600\n",
      "Proceessing : 38700\n",
      "Proceessing : 38800\n",
      "Proceessing : 38900\n",
      "Proceessing : 39000\n",
      "Proceessing : 39100\n",
      "Proceessing : 39200\n",
      "Proceessing : 39300\n",
      "Proceessing : 39400\n",
      "Proceessing : 39500\n",
      "Proceessing : 39600\n",
      "Proceessing : 39700\n",
      "Proceessing : 39800\n",
      "Proceessing : 39900\n",
      "Proceessing : 40000\n",
      "Proceessing : 40100\n",
      "Proceessing : 40200\n",
      "Proceessing : 40300\n",
      "Proceessing : 40400\n",
      "Proceessing : 40500\n",
      "Proceessing : 40600\n",
      "Proceessing : 40700\n",
      "Proceessing : 40800\n",
      "Proceessing : 40900\n",
      "Proceessing : 41000\n",
      "Proceessing : 41100\n",
      "Proceessing : 41200\n",
      "Proceessing : 41300\n",
      "Proceessing : 41400\n",
      "Proceessing : 41500\n",
      "Proceessing : 41600\n",
      "Proceessing : 41700\n",
      "Proceessing : 41800\n",
      "Proceessing : 41900\n",
      "Proceessing : 42000\n",
      "Proceessing : 42100\n",
      "Proceessing : 42200\n",
      "Proceessing : 42300\n",
      "Proceessing : 42400\n",
      "Proceessing : 42500\n",
      "Proceessing : 42600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceessing : 42700\n",
      "Proceessing : 42800\n",
      "Proceessing : 42900\n",
      "Proceessing : 43000\n",
      "Proceessing : 43100\n",
      "Proceessing : 43200\n",
      "Proceessing : 43300\n",
      "Proceessing : 43400\n",
      "Proceessing : 43500\n",
      "Proceessing : 43600\n",
      "Proceessing : 43700\n",
      "Proceessing : 43800\n",
      "Proceessing : 43900\n",
      "Proceessing : 44000\n",
      "Proceessing : 44100\n",
      "Proceessing : 44200\n",
      "Proceessing : 44300\n",
      "Proceessing : 44400\n",
      "Proceessing : 44500\n",
      "Proceessing : 44600\n",
      "Proceessing : 44700\n",
      "Proceessing : 44800\n",
      "Proceessing : 44900\n",
      "Proceessing : 45000\n",
      "Proceessing : 45100\n",
      "Proceessing : 45200\n",
      "Proceessing : 45300\n",
      "Proceessing : 45400\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "dict_words = set(nltk.corpus.words.words())\n",
    "\n",
    "# Remove numeric values, stopwords. Then lemmatize and stem the words\n",
    "def filt(docs):\n",
    "    filtered_words =[]\n",
    "    filtered_docs = [ '' for i in range(len(docs))]\n",
    "    lemma_docs = [ '' for i in range(len(docs))]\n",
    "    for i in range(len(docs)):\n",
    "        if i%100 == 0:\n",
    "            print(\"Proceessing : \"+ str(i))\n",
    "        x= str(docs[i])\n",
    "        words = re.split(\"(?:(?:[^a-zA-Z]+')|(?:'[^a-zA-Z]+))|(?:[^a-zA-Z']+)\", x)\n",
    "        filtered_word_list = [word.lower() for word in words if (( len(word) >= 3 and word.isalpha() and word.lower() not in stop_words ))  ]\n",
    "        filtered_words.append(filtered_word_list)\n",
    "        for word in filtered_word_list:\n",
    "            lemma_docs[i] = lemma_docs[i] + lemma.lemmatize(word) + \" \"\n",
    "    return lemma_docs\n",
    "overview_filtered = filt(overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2HJR-D8tRof2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y1HWhs1uQyrQ"
   },
   "outputs": [],
   "source": [
    "class DocIterator(object):\n",
    "    def __init__(self, doc_list, labels_list):\n",
    "        self.labels_list = labels_list\n",
    "        self.doc_list = doc_list\n",
    "\n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.doc_list):\n",
    "            yield TaggedDocument(words=re.split('\\W+',doc), tags=[self.labels_list[idx]])\n",
    "iterator = DocIterator(overview_filtered, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "Ez_OChABTHt1",
    "outputId": "1200a56e-ec13-45af-cd5f-85cd2d649137"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-30 18:05:45,342 : WARNING : consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-08-30 18:05:45,346 : INFO : collecting all words and their counts\n",
      "2019-08-30 18:05:45,348 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2019-08-30 18:05:45,614 : INFO : PROGRESS: at example #10000, processed 313484 words (1193572/s), 28322 word types, 9768 tags\n",
      "2019-08-30 18:05:45,839 : INFO : PROGRESS: at example #20000, processed 624237 words (1379116/s), 41629 word types, 19334 tags\n",
      "2019-08-30 18:05:46,068 : INFO : PROGRESS: at example #30000, processed 935119 words (1366416/s), 51266 word types, 28696 tags\n",
      "2019-08-30 18:05:46,300 : INFO : PROGRESS: at example #40000, processed 1256548 words (1386133/s), 61832 word types, 38182 tags\n",
      "2019-08-30 18:05:46,457 : INFO : collected 66181 word types and 43373 unique tags from a corpus of 45466 examples and 1418579 words\n",
      "2019-08-30 18:05:46,458 : INFO : Loading a fresh vocabulary\n",
      "2019-08-30 18:05:46,544 : INFO : effective_min_count=2 retains 36974 unique words (55% of original 66181, drops 29207)\n",
      "2019-08-30 18:05:46,545 : INFO : effective_min_count=2 leaves 1389372 word corpus (97% of original 1418579, drops 29207)\n",
      "2019-08-30 18:05:46,680 : INFO : deleting the raw counts dictionary of 66181 items\n",
      "2019-08-30 18:05:46,682 : INFO : sample=0.001 downsamples 20 most-common words\n",
      "2019-08-30 18:05:46,682 : INFO : downsampling leaves estimated 1325006 word corpus (95.4% of prior 1389372)\n",
      "2019-08-30 18:05:46,829 : INFO : estimated required memory for 36974 words and 150 dimensions: 97554200 bytes\n",
      "2019-08-30 18:05:46,829 : INFO : resetting layer weights\n",
      "2019-08-30 18:05:47,795 : INFO : training model with 4 workers on 36974 vocabulary and 150 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done building vocabulary\n",
      "start training the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-30 18:05:48,867 : INFO : EPOCH 1 - PROGRESS: at 23.13% examples, 300382 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:05:49,875 : INFO : EPOCH 1 - PROGRESS: at 44.95% examples, 298467 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:05:50,947 : INFO : EPOCH 1 - PROGRESS: at 68.24% examples, 297897 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:05:52,010 : INFO : EPOCH 1 - PROGRESS: at 93.03% examples, 304781 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:05:52,160 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:05:52,165 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:05:52,254 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:05:52,279 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:05:52,282 : INFO : EPOCH - 1 : training on 1418579 raw words (1370415 effective words) took 4.5s, 306042 effective words/s\n",
      "2019-08-30 18:05:53,330 : INFO : EPOCH 2 - PROGRESS: at 12.00% examples, 161947 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:05:54,451 : INFO : EPOCH 2 - PROGRESS: at 28.96% examples, 185488 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:05:55,452 : INFO : EPOCH 2 - PROGRESS: at 47.77% examples, 209175 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:05:56,566 : INFO : EPOCH 2 - PROGRESS: at 64.14% examples, 206638 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:05:57,588 : INFO : EPOCH 2 - PROGRESS: at 84.74% examples, 221163 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:05:58,377 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:05:58,389 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:05:58,457 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:05:58,463 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:05:58,463 : INFO : EPOCH - 2 : training on 1418579 raw words (1370569 effective words) took 6.2s, 222813 effective words/s\n",
      "2019-08-30 18:05:59,476 : INFO : EPOCH 3 - PROGRESS: at 14.76% examples, 202735 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:00,531 : INFO : EPOCH 3 - PROGRESS: at 28.96% examples, 192732 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:01,591 : INFO : EPOCH 3 - PROGRESS: at 54.07% examples, 238560 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:06:02,618 : INFO : EPOCH 3 - PROGRESS: at 79.27% examples, 263080 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:03,322 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:06:03,327 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:06:03,402 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:06:03,412 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:06:03,413 : INFO : EPOCH - 3 : training on 1418579 raw words (1370580 effective words) took 4.9s, 277478 effective words/s\n",
      "2019-08-30 18:06:04,451 : INFO : EPOCH 4 - PROGRESS: at 23.13% examples, 310958 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:05,503 : INFO : EPOCH 4 - PROGRESS: at 48.46% examples, 320434 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:06,566 : INFO : EPOCH 4 - PROGRESS: at 68.24% examples, 298093 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:07,620 : INFO : EPOCH 4 - PROGRESS: at 93.04% examples, 305555 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:07,805 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:06:07,819 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:06:07,862 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:06:07,868 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:06:07,871 : INFO : EPOCH - 4 : training on 1418579 raw words (1370475 effective words) took 4.4s, 308185 effective words/s\n",
      "2019-08-30 18:06:09,018 : INFO : EPOCH 5 - PROGRESS: at 12.00% examples, 144935 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:10,077 : INFO : EPOCH 5 - PROGRESS: at 37.32% examples, 233277 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:11,122 : INFO : EPOCH 5 - PROGRESS: at 59.88% examples, 253327 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:06:12,190 : INFO : EPOCH 5 - PROGRESS: at 78.55% examples, 250806 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:13,213 : INFO : EPOCH 5 - PROGRESS: at 88.73% examples, 229645 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:13,644 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:06:13,663 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:06:13,748 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:06:13,753 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:06:13,754 : INFO : EPOCH - 5 : training on 1418579 raw words (1370406 effective words) took 5.9s, 233320 effective words/s\n",
      "2019-08-30 18:06:15,017 : INFO : EPOCH 6 - PROGRESS: at 17.58% examples, 194979 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:16,054 : INFO : EPOCH 6 - PROGRESS: at 42.88% examples, 258528 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:17,095 : INFO : EPOCH 6 - PROGRESS: at 68.24% examples, 282136 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:06:18,125 : INFO : EPOCH 6 - PROGRESS: at 91.58% examples, 290351 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:18,404 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:06:18,406 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:06:18,455 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:06:18,469 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:06:18,472 : INFO : EPOCH - 6 : training on 1418579 raw words (1370642 effective words) took 4.7s, 291767 effective words/s\n",
      "2019-08-30 18:06:19,551 : INFO : EPOCH 7 - PROGRESS: at 14.76% examples, 191977 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:20,650 : INFO : EPOCH 7 - PROGRESS: at 37.32% examples, 237370 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:06:21,722 : INFO : EPOCH 7 - PROGRESS: at 45.67% examples, 194311 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:22,767 : INFO : EPOCH 7 - PROGRESS: at 54.07% examples, 173922 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:23,787 : INFO : EPOCH 7 - PROGRESS: at 61.96% examples, 160483 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:24,960 : INFO : EPOCH 7 - PROGRESS: at 67.54% examples, 143314 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:26,321 : INFO : EPOCH 7 - PROGRESS: at 75.91% examples, 133138 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:27,385 : INFO : EPOCH 7 - PROGRESS: at 86.02% examples, 133370 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:28,240 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:06:28,275 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:06:28,295 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:06:28,302 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:06:28,302 : INFO : EPOCH - 7 : training on 1418579 raw words (1370507 effective words) took 9.8s, 139695 effective words/s\n",
      "2019-08-30 18:06:29,318 : INFO : EPOCH 8 - PROGRESS: at 14.05% examples, 192519 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:30,371 : INFO : EPOCH 8 - PROGRESS: at 31.79% examples, 211331 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:06:31,471 : INFO : EPOCH 8 - PROGRESS: at 51.22% examples, 223150 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:32,487 : INFO : EPOCH 8 - PROGRESS: at 68.94% examples, 226630 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:33,509 : INFO : EPOCH 8 - PROGRESS: at 88.73% examples, 235614 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:34,119 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:06:34,151 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:06:34,231 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:06:34,247 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-30 18:06:34,248 : INFO : EPOCH - 8 : training on 1418579 raw words (1370226 effective words) took 5.9s, 230806 effective words/s\n",
      "2019-08-30 18:06:35,278 : INFO : EPOCH 9 - PROGRESS: at 18.28% examples, 247889 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:36,304 : INFO : EPOCH 9 - PROGRESS: at 34.59% examples, 232095 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:06:37,365 : INFO : EPOCH 9 - PROGRESS: at 40.14% examples, 177573 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:38,409 : INFO : EPOCH 9 - PROGRESS: at 56.94% examples, 188670 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:39,411 : INFO : EPOCH 9 - PROGRESS: at 73.14% examples, 194986 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:40,547 : INFO : EPOCH 9 - PROGRESS: at 93.03% examples, 203982 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:40,679 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:06:40,683 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:06:40,725 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:06:40,726 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:06:40,726 : INFO : EPOCH - 9 : training on 1418579 raw words (1370462 effective words) took 6.5s, 212003 effective words/s\n",
      "2019-08-30 18:06:41,738 : INFO : EPOCH 10 - PROGRESS: at 17.58% examples, 241745 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:06:42,766 : INFO : EPOCH 10 - PROGRESS: at 40.14% examples, 271409 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:06:43,882 : INFO : EPOCH 10 - PROGRESS: at 56.23% examples, 245650 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:44,901 : INFO : EPOCH 10 - PROGRESS: at 74.43% examples, 245698 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:06:45,962 : INFO : EPOCH 10 - PROGRESS: at 93.04% examples, 245352 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:46,119 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:06:46,131 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:06:46,156 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:06:46,161 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:06:46,162 : INFO : EPOCH - 10 : training on 1418579 raw words (1370296 effective words) took 5.4s, 252550 effective words/s\n",
      "2019-08-30 18:06:47,178 : INFO : EPOCH 11 - PROGRESS: at 12.70% examples, 173382 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:06:48,184 : INFO : EPOCH 11 - PROGRESS: at 32.48% examples, 221085 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:49,209 : INFO : EPOCH 11 - PROGRESS: at 56.94% examples, 257610 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:50,215 : INFO : EPOCH 11 - PROGRESS: at 74.56% examples, 253073 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:51,245 : INFO : EPOCH 11 - PROGRESS: at 87.32% examples, 237646 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:51,965 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:06:51,971 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:06:52,043 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:06:52,052 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:06:52,054 : INFO : EPOCH - 11 : training on 1418579 raw words (1370466 effective words) took 5.9s, 233020 effective words/s\n",
      "2019-08-30 18:06:53,115 : INFO : EPOCH 12 - PROGRESS: at 8.48% examples, 113075 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:54,253 : INFO : EPOCH 12 - PROGRESS: at 20.37% examples, 129615 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:55,372 : INFO : EPOCH 12 - PROGRESS: at 34.59% examples, 144220 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:56,417 : INFO : EPOCH 12 - PROGRESS: at 43.57% examples, 138333 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:57,726 : INFO : EPOCH 12 - PROGRESS: at 54.77% examples, 133612 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:58,802 : INFO : EPOCH 12 - PROGRESS: at 66.92% examples, 136638 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:06:59,844 : INFO : EPOCH 12 - PROGRESS: at 77.24% examples, 136869 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:00,868 : INFO : EPOCH 12 - PROGRESS: at 90.83% examples, 142732 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:01,346 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:07:01,365 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:07:01,398 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:07:01,418 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:07:01,420 : INFO : EPOCH - 12 : training on 1418579 raw words (1370544 effective words) took 9.3s, 146833 effective words/s\n",
      "2019-08-30 18:07:02,614 : INFO : EPOCH 13 - PROGRESS: at 12.00% examples, 140539 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:07:03,714 : INFO : EPOCH 13 - PROGRESS: at 20.37% examples, 123526 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:07:04,855 : INFO : EPOCH 13 - PROGRESS: at 34.59% examples, 138824 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:06,039 : INFO : EPOCH 13 - PROGRESS: at 45.62% examples, 136567 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:07,095 : INFO : EPOCH 13 - PROGRESS: at 59.86% examples, 145266 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:08,117 : INFO : EPOCH 13 - PROGRESS: at 73.14% examples, 150415 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:07:09,132 : INFO : EPOCH 13 - PROGRESS: at 87.41% examples, 156758 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:09,499 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:07:09,501 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:07:09,549 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:07:09,553 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:07:09,553 : INFO : EPOCH - 13 : training on 1418579 raw words (1370647 effective words) took 8.1s, 168986 effective words/s\n",
      "2019-08-30 18:07:10,696 : INFO : EPOCH 14 - PROGRESS: at 19.00% examples, 230721 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:11,900 : INFO : EPOCH 14 - PROGRESS: at 40.14% examples, 235764 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:07:12,954 : INFO : EPOCH 14 - PROGRESS: at 58.39% examples, 236452 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:07:13,981 : INFO : EPOCH 14 - PROGRESS: at 81.87% examples, 255422 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:07:14,611 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:07:14,615 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:07:14,633 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:07:14,637 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:07:14,639 : INFO : EPOCH - 14 : training on 1418579 raw words (1370537 effective words) took 5.1s, 270033 effective words/s\n",
      "2019-08-30 18:07:15,661 : INFO : EPOCH 15 - PROGRESS: at 21.71% examples, 298627 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:16,719 : INFO : EPOCH 15 - PROGRESS: at 45.62% examples, 304341 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:17,733 : INFO : EPOCH 15 - PROGRESS: at 61.29% examples, 273100 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:18,798 : INFO : EPOCH 15 - PROGRESS: at 79.27% examples, 263170 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:19,511 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:07:19,523 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:07:19,553 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:07:19,557 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:07:19,557 : INFO : EPOCH - 15 : training on 1418579 raw words (1370015 effective words) took 4.9s, 279570 effective words/s\n",
      "2019-08-30 18:07:20,623 : INFO : EPOCH 16 - PROGRESS: at 23.13% examples, 302240 words/s, in_qsize 8, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-30 18:07:21,659 : INFO : EPOCH 16 - PROGRESS: at 48.46% examples, 318536 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:22,666 : INFO : EPOCH 16 - PROGRESS: at 72.41% examples, 320753 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:23,675 : INFO : EPOCH 16 - PROGRESS: at 98.29% examples, 328494 words/s, in_qsize 3, out_qsize 1\n",
      "2019-08-30 18:07:23,677 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:07:23,681 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:07:23,713 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:07:23,717 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:07:23,717 : INFO : EPOCH - 16 : training on 1418579 raw words (1370361 effective words) took 4.2s, 330178 effective words/s\n",
      "2019-08-30 18:07:24,736 : INFO : EPOCH 17 - PROGRESS: at 20.37% examples, 278280 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:07:25,790 : INFO : EPOCH 17 - PROGRESS: at 41.50% examples, 276383 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:26,810 : INFO : EPOCH 17 - PROGRESS: at 65.49% examples, 291396 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:07:27,842 : INFO : EPOCH 17 - PROGRESS: at 90.13% examples, 302248 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:28,088 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:07:28,098 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:07:28,123 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:07:28,128 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:07:28,129 : INFO : EPOCH - 17 : training on 1418579 raw words (1370515 effective words) took 4.4s, 311373 effective words/s\n",
      "2019-08-30 18:07:29,139 : INFO : EPOCH 18 - PROGRESS: at 21.71% examples, 299827 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:30,154 : INFO : EPOCH 18 - PROGRESS: at 45.62% examples, 311385 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:31,181 : INFO : EPOCH 18 - PROGRESS: at 71.09% examples, 320429 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:32,181 : INFO : EPOCH 18 - PROGRESS: at 96.71% examples, 329040 words/s, in_qsize 5, out_qsize 0\n",
      "2019-08-30 18:07:32,210 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:07:32,221 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:07:32,250 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:07:32,251 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:07:32,252 : INFO : EPOCH - 18 : training on 1418579 raw words (1370609 effective words) took 4.1s, 333161 effective words/s\n",
      "2019-08-30 18:07:33,268 : INFO : EPOCH 19 - PROGRESS: at 17.58% examples, 241712 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:34,317 : INFO : EPOCH 19 - PROGRESS: at 40.14% examples, 268675 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:35,333 : INFO : EPOCH 19 - PROGRESS: at 64.14% examples, 286632 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:07:36,340 : INFO : EPOCH 19 - PROGRESS: at 83.33% examples, 281695 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:36,956 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:07:36,964 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:07:36,988 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:07:36,991 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:07:36,992 : INFO : EPOCH - 19 : training on 1418579 raw words (1370420 effective words) took 4.7s, 290011 effective words/s\n",
      "2019-08-30 18:07:38,016 : INFO : EPOCH 20 - PROGRESS: at 21.04% examples, 287628 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:39,058 : INFO : EPOCH 20 - PROGRESS: at 45.62% examples, 305958 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:40,108 : INFO : EPOCH 20 - PROGRESS: at 63.39% examples, 280230 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:07:41,119 : INFO : EPOCH 20 - PROGRESS: at 87.32% examples, 293010 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:41,655 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:07:41,666 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:07:41,678 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:07:41,682 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:07:41,682 : INFO : EPOCH - 20 : training on 1418579 raw words (1370279 effective words) took 4.7s, 293036 effective words/s\n",
      "2019-08-30 18:07:42,693 : INFO : EPOCH 21 - PROGRESS: at 19.68% examples, 270244 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:43,728 : INFO : EPOCH 21 - PROGRESS: at 42.88% examples, 289151 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:44,779 : INFO : EPOCH 21 - PROGRESS: at 68.24% examples, 303164 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:45,784 : INFO : EPOCH 21 - PROGRESS: at 88.73% examples, 299076 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:46,151 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:07:46,163 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:07:46,183 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:07:46,189 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:07:46,190 : INFO : EPOCH - 21 : training on 1418579 raw words (1370526 effective words) took 4.5s, 304521 effective words/s\n",
      "2019-08-30 18:07:47,257 : INFO : EPOCH 22 - PROGRESS: at 23.13% examples, 303396 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:48,316 : INFO : EPOCH 22 - PROGRESS: at 40.14% examples, 260858 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:49,319 : INFO : EPOCH 22 - PROGRESS: at 59.16% examples, 260476 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:50,367 : INFO : EPOCH 22 - PROGRESS: at 81.87% examples, 271054 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:50,994 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:07:51,003 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:07:51,032 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:07:51,034 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:07:51,035 : INFO : EPOCH - 22 : training on 1418579 raw words (1370312 effective words) took 4.8s, 283710 effective words/s\n",
      "2019-08-30 18:07:52,050 : INFO : EPOCH 23 - PROGRESS: at 22.42% examples, 309589 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:53,067 : INFO : EPOCH 23 - PROGRESS: at 42.88% examples, 292092 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:54,079 : INFO : EPOCH 23 - PROGRESS: at 59.86% examples, 270986 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:07:55,139 : INFO : EPOCH 23 - PROGRESS: at 73.85% examples, 247822 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:07:56,184 : INFO : EPOCH 23 - PROGRESS: at 86.02% examples, 230962 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:07:56,839 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:07:56,843 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:07:56,911 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:07:56,912 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:07:56,914 : INFO : EPOCH - 23 : training on 1418579 raw words (1370357 effective words) took 5.9s, 233682 effective words/s\n",
      "2019-08-30 18:07:57,940 : INFO : EPOCH 24 - PROGRESS: at 20.37% examples, 277916 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:07:58,954 : INFO : EPOCH 24 - PROGRESS: at 28.96% examples, 195942 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:00,029 : INFO : EPOCH 24 - PROGRESS: at 54.07% examples, 239998 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:01,032 : INFO : EPOCH 24 - PROGRESS: at 78.55% examples, 263483 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:01,810 : INFO : worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-30 18:08:01,816 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:08:01,886 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:08:01,895 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:08:01,896 : INFO : EPOCH - 24 : training on 1418579 raw words (1370522 effective words) took 5.0s, 275935 effective words/s\n",
      "2019-08-30 18:08:02,914 : INFO : EPOCH 25 - PROGRESS: at 22.42% examples, 308139 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:03,945 : INFO : EPOCH 25 - PROGRESS: at 45.67% examples, 308397 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:04,951 : INFO : EPOCH 25 - PROGRESS: at 66.18% examples, 298515 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:05,988 : INFO : EPOCH 25 - PROGRESS: at 90.13% examples, 304941 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:06,266 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:08:06,280 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:08:06,372 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:08:06,384 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:08:06,385 : INFO : EPOCH - 25 : training on 1418579 raw words (1370682 effective words) took 4.5s, 306224 effective words/s\n",
      "2019-08-30 18:08:07,450 : INFO : EPOCH 26 - PROGRESS: at 23.13% examples, 302542 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:08,485 : INFO : EPOCH 26 - PROGRESS: at 48.44% examples, 318704 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:09,519 : INFO : EPOCH 26 - PROGRESS: at 73.73% examples, 324398 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:10,454 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:08:10,477 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:08:10,554 : INFO : EPOCH 26 - PROGRESS: at 99.21% examples, 327173 words/s, in_qsize 1, out_qsize 1\n",
      "2019-08-30 18:08:10,560 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:08:10,569 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:08:10,572 : INFO : EPOCH - 26 : training on 1418579 raw words (1370807 effective words) took 4.2s, 328083 effective words/s\n",
      "2019-08-30 18:08:11,620 : INFO : EPOCH 27 - PROGRESS: at 17.58% examples, 235661 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:12,654 : INFO : EPOCH 27 - PROGRESS: at 42.88% examples, 285801 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:13,698 : INFO : EPOCH 27 - PROGRESS: at 68.24% examples, 301633 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:14,743 : INFO : EPOCH 27 - PROGRESS: at 93.04% examples, 308906 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:14,925 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:08:14,937 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:08:14,987 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:08:15,000 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:08:15,002 : INFO : EPOCH - 27 : training on 1418579 raw words (1370643 effective words) took 4.4s, 310824 effective words/s\n",
      "2019-08-30 18:08:16,019 : INFO : EPOCH 28 - PROGRESS: at 22.42% examples, 308620 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:08:17,033 : INFO : EPOCH 28 - PROGRESS: at 45.67% examples, 311283 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:18,072 : INFO : EPOCH 28 - PROGRESS: at 71.09% examples, 318989 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:19,128 : INFO : EPOCH 28 - PROGRESS: at 84.74% examples, 283659 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:08:19,615 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:08:19,648 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:08:19,724 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:08:19,735 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:08:19,736 : INFO : EPOCH - 28 : training on 1418579 raw words (1370210 effective words) took 4.7s, 290280 effective words/s\n",
      "2019-08-30 18:08:20,833 : INFO : EPOCH 29 - PROGRESS: at 20.37% examples, 260988 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:08:21,880 : INFO : EPOCH 29 - PROGRESS: at 45.62% examples, 295729 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:08:22,931 : INFO : EPOCH 29 - PROGRESS: at 71.04% examples, 307223 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:23,964 : INFO : EPOCH 29 - PROGRESS: at 95.98% examples, 313878 words/s, in_qsize 6, out_qsize 0\n",
      "2019-08-30 18:08:24,039 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:08:24,049 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:08:24,120 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:08:24,125 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:08:24,126 : INFO : EPOCH - 29 : training on 1418579 raw words (1370191 effective words) took 4.4s, 313637 effective words/s\n",
      "2019-08-30 18:08:25,195 : INFO : EPOCH 30 - PROGRESS: at 20.37% examples, 265924 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:26,213 : INFO : EPOCH 30 - PROGRESS: at 40.14% examples, 265587 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:27,251 : INFO : EPOCH 30 - PROGRESS: at 65.49% examples, 288597 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:28,305 : INFO : EPOCH 30 - PROGRESS: at 90.13% examples, 298486 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:28,587 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:08:28,590 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:08:28,666 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:08:28,675 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:08:28,676 : INFO : EPOCH - 30 : training on 1418579 raw words (1370021 effective words) took 4.5s, 301971 effective words/s\n",
      "2019-08-30 18:08:29,774 : INFO : EPOCH 31 - PROGRESS: at 23.13% examples, 302875 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:30,814 : INFO : EPOCH 31 - PROGRESS: at 48.46% examples, 318191 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:31,828 : INFO : EPOCH 31 - PROGRESS: at 73.14% examples, 322827 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:32,867 : INFO : EPOCH 31 - PROGRESS: at 93.04% examples, 309062 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:33,061 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:08:33,067 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:08:33,105 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:08:33,117 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:08:33,124 : INFO : EPOCH - 31 : training on 1418579 raw words (1370478 effective words) took 4.4s, 311128 effective words/s\n",
      "2019-08-30 18:08:34,144 : INFO : EPOCH 32 - PROGRESS: at 22.42% examples, 308700 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:08:35,158 : INFO : EPOCH 32 - PROGRESS: at 45.67% examples, 311194 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:36,213 : INFO : EPOCH 32 - PROGRESS: at 71.09% examples, 317314 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:37,218 : INFO : EPOCH 32 - PROGRESS: at 95.94% examples, 323883 words/s, in_qsize 6, out_qsize 0\n",
      "2019-08-30 18:08:37,282 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:08:37,289 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:08:37,356 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:08:37,362 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:08:37,363 : INFO : EPOCH - 32 : training on 1418579 raw words (1370477 effective words) took 4.2s, 324559 effective words/s\n",
      "2019-08-30 18:08:38,450 : INFO : EPOCH 33 - PROGRESS: at 23.13% examples, 297220 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:08:39,502 : INFO : EPOCH 33 - PROGRESS: at 48.44% examples, 313303 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-30 18:08:40,519 : INFO : EPOCH 33 - PROGRESS: at 68.24% examples, 297889 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:41,529 : INFO : EPOCH 33 - PROGRESS: at 93.04% examples, 308648 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:41,700 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:08:41,710 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:08:41,783 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:08:41,790 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:08:41,791 : INFO : EPOCH - 33 : training on 1418579 raw words (1370615 effective words) took 4.4s, 310323 effective words/s\n",
      "2019-08-30 18:08:42,827 : INFO : EPOCH 34 - PROGRESS: at 23.13% examples, 312348 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:43,885 : INFO : EPOCH 34 - PROGRESS: at 48.46% examples, 320407 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:08:44,926 : INFO : EPOCH 34 - PROGRESS: at 73.73% examples, 324760 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:45,860 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:08:45,862 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:08:45,929 : INFO : EPOCH 34 - PROGRESS: at 99.21% examples, 329995 words/s, in_qsize 1, out_qsize 1\n",
      "2019-08-30 18:08:45,930 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:08:45,936 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:08:45,937 : INFO : EPOCH - 34 : training on 1418579 raw words (1370487 effective words) took 4.1s, 331615 effective words/s\n",
      "2019-08-30 18:08:46,959 : INFO : EPOCH 35 - PROGRESS: at 22.42% examples, 307981 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:47,973 : INFO : EPOCH 35 - PROGRESS: at 42.21% examples, 287057 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:48,979 : INFO : EPOCH 35 - PROGRESS: at 65.49% examples, 296858 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:08:50,019 : INFO : EPOCH 35 - PROGRESS: at 90.14% examples, 305845 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:50,307 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:08:50,312 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:08:50,361 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:08:50,365 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:08:50,366 : INFO : EPOCH - 35 : training on 1418579 raw words (1370137 effective words) took 4.4s, 310529 effective words/s\n",
      "2019-08-30 18:08:51,436 : INFO : EPOCH 36 - PROGRESS: at 23.13% examples, 300631 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:52,480 : INFO : EPOCH 36 - PROGRESS: at 48.44% examples, 316474 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:53,494 : INFO : EPOCH 36 - PROGRESS: at 73.14% examples, 321741 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:54,502 : INFO : EPOCH 36 - PROGRESS: at 90.83% examples, 303609 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:54,775 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:08:54,787 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:08:54,846 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:08:54,853 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:08:54,854 : INFO : EPOCH - 36 : training on 1418579 raw words (1370560 effective words) took 4.5s, 305897 effective words/s\n",
      "2019-08-30 18:08:55,869 : INFO : EPOCH 37 - PROGRESS: at 12.71% examples, 173695 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:56,934 : INFO : EPOCH 37 - PROGRESS: at 31.79% examples, 210416 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:57,950 : INFO : EPOCH 37 - PROGRESS: at 55.46% examples, 247381 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:08:58,957 : INFO : EPOCH 37 - PROGRESS: at 75.75% examples, 254831 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:08:59,847 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:08:59,856 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:08:59,879 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:08:59,881 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:08:59,882 : INFO : EPOCH - 37 : training on 1418579 raw words (1370459 effective words) took 5.0s, 273225 effective words/s\n",
      "2019-08-30 18:09:00,937 : INFO : EPOCH 38 - PROGRESS: at 20.37% examples, 268408 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:01,959 : INFO : EPOCH 38 - PROGRESS: at 38.74% examples, 256978 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:09:02,979 : INFO : EPOCH 38 - PROGRESS: at 61.29% examples, 272080 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:09:03,988 : INFO : EPOCH 38 - PROGRESS: at 83.33% examples, 280082 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:09:04,569 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:09:04,574 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:09:04,603 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:09:04,605 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:09:04,605 : INFO : EPOCH - 38 : training on 1418579 raw words (1370508 effective words) took 4.7s, 290664 effective words/s\n",
      "2019-08-30 18:09:05,721 : INFO : EPOCH 39 - PROGRESS: at 20.37% examples, 255150 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:06,731 : INFO : EPOCH 39 - PROGRESS: at 43.57% examples, 283829 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:09:07,754 : INFO : EPOCH 39 - PROGRESS: at 68.94% examples, 302075 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:09:08,757 : INFO : EPOCH 39 - PROGRESS: at 91.58% examples, 305373 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:09:08,969 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:09:08,975 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:09:08,993 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:09:08,994 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:09:08,994 : INFO : EPOCH - 39 : training on 1418579 raw words (1370516 effective words) took 4.4s, 313324 effective words/s\n",
      "2019-08-30 18:09:10,021 : INFO : EPOCH 40 - PROGRESS: at 17.58% examples, 238252 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:11,058 : INFO : EPOCH 40 - PROGRESS: at 42.88% examples, 286909 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:09:12,064 : INFO : EPOCH 40 - PROGRESS: at 66.18% examples, 296749 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:13,139 : INFO : EPOCH 40 - PROGRESS: at 90.13% examples, 300838 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:09:13,350 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:09:13,360 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:09:13,401 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:09:13,402 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:09:13,403 : INFO : EPOCH - 40 : training on 1418579 raw words (1370549 effective words) took 4.4s, 311569 effective words/s\n",
      "2019-08-30 18:09:14,480 : INFO : EPOCH 41 - PROGRESS: at 23.13% examples, 299483 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:15,545 : INFO : EPOCH 41 - PROGRESS: at 45.67% examples, 294575 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:16,566 : INFO : EPOCH 41 - PROGRESS: at 64.10% examples, 278783 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:17,588 : INFO : EPOCH 41 - PROGRESS: at 87.32% examples, 288723 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:17,944 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:09:17,945 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:09:17,983 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:09:17,988 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-30 18:09:17,988 : INFO : EPOCH - 41 : training on 1418579 raw words (1370552 effective words) took 4.6s, 299549 effective words/s\n",
      "2019-08-30 18:09:19,016 : INFO : EPOCH 42 - PROGRESS: at 14.05% examples, 191314 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:20,019 : INFO : EPOCH 42 - PROGRESS: at 32.48% examples, 220749 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:21,089 : INFO : EPOCH 42 - PROGRESS: at 56.94% examples, 253560 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:22,094 : INFO : EPOCH 42 - PROGRESS: at 79.85% examples, 268899 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:22,774 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:09:22,779 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:09:22,814 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:09:22,819 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:09:22,820 : INFO : EPOCH - 42 : training on 1418579 raw words (1370592 effective words) took 4.8s, 284572 effective words/s\n",
      "2019-08-30 18:09:23,895 : INFO : EPOCH 43 - PROGRESS: at 20.37% examples, 264139 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:24,923 : INFO : EPOCH 43 - PROGRESS: at 40.14% examples, 263349 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:25,976 : INFO : EPOCH 43 - PROGRESS: at 62.70% examples, 273375 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:27,028 : INFO : EPOCH 43 - PROGRESS: at 84.74% examples, 278113 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:27,510 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:09:27,519 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:09:27,556 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:09:27,560 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:09:27,561 : INFO : EPOCH - 43 : training on 1418579 raw words (1370558 effective words) took 4.7s, 289843 effective words/s\n",
      "2019-08-30 18:09:28,677 : INFO : EPOCH 44 - PROGRESS: at 23.13% examples, 294692 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:29,812 : INFO : EPOCH 44 - PROGRESS: at 48.46% examples, 300324 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:30,828 : INFO : EPOCH 44 - PROGRESS: at 73.14% examples, 310261 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:31,892 : INFO : EPOCH 44 - PROGRESS: at 93.04% examples, 298193 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:09:32,034 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:09:32,041 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:09:32,068 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:09:32,076 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:09:32,076 : INFO : EPOCH - 44 : training on 1418579 raw words (1370429 effective words) took 4.5s, 305640 effective words/s\n",
      "2019-08-30 18:09:33,149 : INFO : EPOCH 45 - PROGRESS: at 23.13% examples, 299734 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:34,173 : INFO : EPOCH 45 - PROGRESS: at 48.46% examples, 319060 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:35,201 : INFO : EPOCH 45 - PROGRESS: at 73.85% examples, 325087 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:36,107 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:09:36,113 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:09:36,154 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:09:36,159 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:09:36,160 : INFO : EPOCH - 45 : training on 1418579 raw words (1370401 effective words) took 4.1s, 336187 effective words/s\n",
      "2019-08-30 18:09:37,175 : INFO : EPOCH 46 - PROGRESS: at 20.35% examples, 279536 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:09:38,186 : INFO : EPOCH 46 - PROGRESS: at 45.67% examples, 311279 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:39,193 : INFO : EPOCH 46 - PROGRESS: at 65.49% examples, 297088 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:40,206 : INFO : EPOCH 46 - PROGRESS: at 88.73% examples, 303396 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:40,535 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:09:40,543 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:09:40,574 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:09:40,577 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:09:40,578 : INFO : EPOCH - 46 : training on 1418579 raw words (1370233 effective words) took 4.4s, 310853 effective words/s\n",
      "2019-08-30 18:09:41,601 : INFO : EPOCH 47 - PROGRESS: at 17.58% examples, 238810 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:42,604 : INFO : EPOCH 47 - PROGRESS: at 42.21% examples, 287402 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:09:43,618 : INFO : EPOCH 47 - PROGRESS: at 64.14% examples, 290025 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:44,622 : INFO : EPOCH 47 - PROGRESS: at 86.02% examples, 293951 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:09:45,091 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:09:45,098 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:09:45,145 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:09:45,150 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:09:45,150 : INFO : EPOCH - 47 : training on 1418579 raw words (1370475 effective words) took 4.6s, 300332 effective words/s\n",
      "2019-08-30 18:09:46,213 : INFO : EPOCH 48 - PROGRESS: at 17.58% examples, 229486 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:47,250 : INFO : EPOCH 48 - PROGRESS: at 42.88% examples, 281739 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:09:48,286 : INFO : EPOCH 48 - PROGRESS: at 68.24% examples, 299440 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:49,297 : INFO : EPOCH 48 - PROGRESS: at 93.04% examples, 309836 words/s, in_qsize 8, out_qsize 0\n",
      "2019-08-30 18:09:49,420 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:09:49,427 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:09:49,466 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:09:49,473 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:09:49,474 : INFO : EPOCH - 48 : training on 1418579 raw words (1370741 effective words) took 4.3s, 317592 effective words/s\n",
      "2019-08-30 18:09:50,550 : INFO : EPOCH 49 - PROGRESS: at 23.13% examples, 302226 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:51,617 : INFO : EPOCH 49 - PROGRESS: at 48.44% examples, 313875 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:52,690 : INFO : EPOCH 49 - PROGRESS: at 69.58% examples, 299039 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:53,719 : INFO : EPOCH 49 - PROGRESS: at 92.30% examples, 301176 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:53,882 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-08-30 18:09:53,909 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:09:53,929 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:09:53,935 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:09:53,936 : INFO : EPOCH - 49 : training on 1418579 raw words (1370589 effective words) took 4.4s, 308505 effective words/s\n",
      "2019-08-30 18:09:54,946 : INFO : EPOCH 50 - PROGRESS: at 20.37% examples, 280520 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:56,019 : INFO : EPOCH 50 - PROGRESS: at 45.67% examples, 302742 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:57,054 : INFO : EPOCH 50 - PROGRESS: at 71.04% examples, 313704 words/s, in_qsize 7, out_qsize 0\n",
      "2019-08-30 18:09:58,057 : INFO : EPOCH 50 - PROGRESS: at 95.98% examples, 321175 words/s, in_qsize 6, out_qsize 0\n",
      "2019-08-30 18:09:58,088 : INFO : worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-30 18:09:58,094 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-08-30 18:09:58,125 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-08-30 18:09:58,130 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-08-30 18:09:58,130 : INFO : EPOCH - 50 : training on 1418579 raw words (1370491 effective words) took 4.2s, 327472 effective words/s\n",
      "2019-08-30 18:09:58,131 : INFO : training on a 70928950 raw words (68523089 effective words) took 250.3s, 273725 effective words/s\n",
      "2019-08-30 18:09:58,131 : INFO : saving Doc2Vec object under doc2vec_Movie_recommender_vec_150_window_10_mc_2_epochs_50.model, separately None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250.33632636070251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-08-30 18:09:59,055 : INFO : saved doc2vec_Movie_recommender_vec_150_window_10_mc_2_epochs_50.model\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Doc2Vec(vector_size=150, window=10, min_count=2, workers=4, alpha=0.025, min_alpha=0.001)\n",
    "model.build_vocab(iterator)\n",
    "\n",
    "print('done building vocabulary')\n",
    "print('start training the model')\n",
    "tic = time.time()\n",
    "model.train(iterator,total_examples=model.corpus_count, epochs = 50)\n",
    "toc = time.time()\n",
    "print(toc-tic)\n",
    "model.save(\"doc2vec_Movie_recommender_vec_150_window_10_mc_2_epochs_50.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "r5bBQASxTc0O",
    "outputId": "632af4fb-591b-441a-9def-ac6accf4eb38"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-32e6811a092b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, indexer)\u001b[0m\n\u001b[1;32m   1639\u001b[0m         negative = [\n\u001b[1;32m   1640\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minteger_types\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1641\u001b[0;31m             \u001b[0;32melse\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1642\u001b[0m         ]\n\u001b[1;32m   1643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "model.docvecs.most_similar(title[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wFTG-EbAT34k"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled11.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
